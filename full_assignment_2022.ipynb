{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "KeJxAKSvNfNy"
   },
   "source": [
    "# IMDB Database Classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VhIK8UDAgpMu"
   },
   "source": [
    "## Fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8RMZkur0Z7H4"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math \n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=4000)\n",
    "\n",
    "word_index = tf.keras.datasets.imdb.get_word_index()\n",
    "index2word = dict((i + 3, word) for (word, i) in word_index.items())\n",
    "index2word[0] = '[pad]'\n",
    "index2word[1] = '[bos]'\n",
    "index2word[2] = '[oov]'\n",
    "x_train = np.array([' '.join([index2word[idx] for idx in text]) for text in x_train])\n",
    "x_test = np.array([' '.join([index2word[idx] for idx in text]) for text in x_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZoCXNaVXgmXN"
   },
   "source": [
    "## Create the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wP5Xpgpcgl0_",
    "outputId": "e9cee4ea-3b1e-4c87-f370-6e7872726c4b"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "vocabulary = list()\n",
    "train_words = list()\n",
    "sorted_words = list()\n",
    "for text in x_train:\n",
    "  tokens = text.split()\n",
    "  train_words.extend(tokens)\n",
    "\n",
    "Counter = Counter(train_words)\n",
    "Counter_copy = Counter\n",
    "temp = Counter.most_common(3998)\n",
    "for key in temp:\n",
    "    sorted_words.append(key[0])\n",
    "\n",
    "#n=99, m = 1000, k = 2898\n",
    "k=list()\n",
    "n=list()\n",
    "m = Counter.most_common(1100)\n",
    "j=0\n",
    "for key in m:\n",
    "  j+=1\n",
    "  if(j>=101):\n",
    "    vocabulary.append(key[0])\n",
    " \n",
    "\n",
    "for i in range(1,100):\n",
    "  n.append(sorted_words[i])\n",
    "j=0\n",
    "for key in sorted_words:\n",
    "  j+=1\n",
    "  if(j<=1100):\n",
    "    sorted_words.remove(key)\n",
    "k = sorted_words.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDGjmz4UxlRi"
   },
   "source": [
    "## Create binary vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KESrOUVAhmRD",
    "outputId": "077cba85-f8c7-4070-a896-fe7d84e1c4c1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [01:16<00:00, 327.96it/s]\n",
      "100%|██████████| 25000/25000 [01:13<00:00, 342.01it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "x_train_binary = list()\n",
    "x_test_binary = list()\n",
    "\n",
    "for text in tqdm(x_train):\n",
    "  tokens = text.split()\n",
    "  binary_vector = list()\n",
    "  for vocab_token in vocabulary:\n",
    "    if vocab_token in tokens:\n",
    "      binary_vector.append(1)\n",
    "    else:\n",
    "      binary_vector.append(0)\n",
    "  x_train_binary.append(binary_vector)\n",
    "\n",
    "x_train_binary = np.array(x_train_binary)\n",
    "\n",
    "for text in tqdm(x_test):\n",
    "  tokens = text.split()\n",
    "  binary_vector = list()\n",
    "  for vocab_token in vocabulary:\n",
    "    if vocab_token in tokens:\n",
    "      binary_vector.append(1)\n",
    "    else:\n",
    "      binary_vector.append(0)\n",
    "  x_test_binary.append(binary_vector)\n",
    "\n",
    "x_test_binary = np.array(x_test_binary)\n",
    "y_train_list = y_train.tolist()\n",
    "\n",
    "vocabulary_indexes = list()\n",
    "for i in range(len(vocabulary)):\n",
    "  vocabulary_indexes.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gh0UFy2FyCW4"
   },
   "source": [
    "## Naive Bayes classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nT5E13ejyD2f",
    "outputId": "64341573-8b80-43a2-88b4-7f50c404c8a3"
   },
   "outputs": [],
   "source": [
    "class Naive_Bayes:\n",
    "\n",
    "    def __init__(self):\n",
    "        #Λίστες με τις πιθανότητες να έχουμε την κάθε λέξη δεδομένου πως έχουμε αρνητικό ή θετικό review αντίστοιχα\n",
    "        self.x1_while_c_is_negative = list()\n",
    "        self.x1_while_c_is_positive = list()\n",
    "        #καθολικές μεταβλητές με την πιθανότητα να έχουμε αρνητικό review και θετικό review αντιστοιχα\n",
    "        self.p_c0 = float(0)\n",
    "        self.p_c1 = float(0)\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "\n",
    "        reviews = len(Y) \n",
    "\n",
    "        #Υπολογισμός της γενικής πιθανότητας να έχουμε θετικό ή αρνητικό review:\n",
    "        neg_reviews = 0 \n",
    "        pos_reviews = 0\n",
    "        for i in range(len(Y)):\n",
    "            if Y[i] == 0:\n",
    "                neg_reviews += 1\n",
    "            else:\n",
    "                pos_reviews += 1\n",
    "        p_positive_reviews = pos_reviews/reviews\n",
    "        p_negative_reviews = neg_reviews/reviews\n",
    "        #Αποθήκευση του αποτελέσματος τις καθολικές μεταβλητές\n",
    "        self.pc0 = p_negative_reviews\n",
    "        self.pc1 = p_positive_reviews\n",
    "\n",
    "        #Υπολογισμός πιθανοτήτων να έχουμε την κάθε λέξη δεδομένου πως έχουμε αρνητικό ή θετικό review αντίστοιχα:\n",
    "        \n",
    "\n",
    "        #Αρχικοποίηση λιστών με μετρητές\n",
    "        sum_pos = list()\n",
    "        sum_neg = list()\n",
    "        for i in range(0,1000):\n",
    "            sum_pos.append(0) \n",
    "            sum_neg.append(0)\n",
    "\n",
    "        for i in range(len(Y)):\n",
    "            if Y[i] == 0:\n",
    "                j=-1\n",
    "                for word in X[i]:\n",
    "                    j+=1\n",
    "                    if word == 1:\n",
    "                        sum_neg[j] +=1\n",
    "            else:\n",
    "                j=-1\n",
    "                for word in X[i]:\n",
    "                    j+=1\n",
    "                    if word == 1:\n",
    "                        sum_pos[j] +=1\n",
    "\n",
    "        #Λίστες πιθανοτήτων να έχουμε την κάθε λέξη δεδομένου πως έχουμε αρνητικό ή θετικό review \n",
    "        p_ex_pos = list()\n",
    "        p_ex_neg = list()\n",
    "        for i in range(0,1000):\n",
    "            p_ex_pos.append(0) \n",
    "            p_ex_neg.append(0)\n",
    "        #for i in range(len(p_ex_neg_train)):\n",
    "        for i in range(0,1000):\n",
    "            if(sum_neg[i]!=0):\n",
    "                p_ex_neg[i] = sum_neg[i]/neg_reviews #P(Xi = 1 | C = 0)\n",
    "            else:\n",
    "                p_ex_neg[i] = -1 # -1 για τις λέξεις που δεν εμφανίζονται καν\n",
    "        for i in range(0,1000):\n",
    "            if(sum_pos[i]!=0):\n",
    "                p_ex_pos[i] = sum_pos[i]/neg_reviews #P(Xi = 1 | C = 1)\n",
    "            else:\n",
    "                p_ex_pos[i] = -1 # -1 για τις λέξεις που δεν εμφανίζονται καν\n",
    "\n",
    "        self.x1_while_c_is_positive = p_ex_pos.copy()\n",
    "        self.x1_while_c_is_negative = p_ex_neg.copy()\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        predictions = list()\n",
    "        for i in range(len(X)):\n",
    "\n",
    "            #Το pc0 Θα γίνει pc0 = P(C=0)*P(X1=x1 | C=0)*.......*P(Xn = xn| C=0)\n",
    "            pc0 = (self.pc0)   \n",
    "            for xi in range(len(X[i])):\n",
    "                if(x_train_binary[i][xi] == 0):\n",
    "                    pc0 *= (float(1)-self.x1_while_c_is_negative[xi])  \n",
    "                else:\n",
    "                    pc0 *= (self.x1_while_c_is_negative[xi])\n",
    "            pc1 = (self.pc1)\n",
    "            for xi in range(len(X[i])):\n",
    "                if(x_train_binary[i][xi]==1):\n",
    "                    pc1 *= self.x1_while_c_is_positive[xi]\n",
    "                else:\n",
    "                    pc1 *= float(1) - self.x1_while_c_is_positive[xi]\n",
    "            if (pc0<pc1):\n",
    "                predictions.append(1)\n",
    "            else:\n",
    "                predictions.append(0)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Pmh2Gxc-ys1h"
   },
   "source": [
    "## ID3 Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GeOd5C9uyyqI",
    "outputId": "65c0cd08-18e3-4630-b19c-7de464308bab"
   },
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "def IG(class_, feature):\n",
    "  classes = set(class_)\n",
    "\n",
    "  Hc = 0\n",
    "  for c in classes:\n",
    "    pc = list(class_).count(c)/len(class_)\n",
    "    Hc += - pc * math.log(pc, 2)\n",
    "  feature_values = set(feature)\n",
    "\n",
    "  Hc_feature = 0\n",
    "  for feat in feature_values:\n",
    "    \n",
    "    #pf --> P(X=x)\n",
    "    pf = list(feature).count(feat)/len(feature)\n",
    "    indices = [i for i in range(len(feature)) if feature[i] == feat]\n",
    "    clasess_of_feat = [class_[i] for i in indices]\n",
    "    for c in classes:\n",
    "        #pcf --> P(C=c|X=x)\n",
    "        pcf = clasess_of_feat.count(c)/len(clasess_of_feat)\n",
    "        if pcf != 0: \n",
    "            # - P(X=x) * P(C=c|X=x) * log2(P(C=c|X=x))\n",
    "            temp_H = - pf * pcf * math.log(pcf, 2)\n",
    "            #sum for all values of C (class) and X (values of specific feature)\n",
    "            Hc_feature += temp_H\n",
    "  ig = Hc - Hc_feature\n",
    "  return ig\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Tree():\n",
    "    def __init__(self):\n",
    "        self.word = \"no word yet\" #Η λέξη με την οποία θα έγινε το classification ενός υπόδεντρου\n",
    "        self.tag = None #1 αν ο κόμβος έχει reviews με τη λέξη με την οποία έγινε το classification, 0 αν δεν την έχουν\n",
    "        self.children = list() #τα παιδία ενός κόμβου\n",
    "        self.classification = int #Η τελική classification. Παίρνει τιμή μόνο αν έχει γίνει \n",
    "    \n",
    "    def new_child(self, node):\n",
    "        self.children.append(node)\n",
    "\n",
    "class ID3():\n",
    "    def __init__(self, max_depth = 10):\n",
    "        self.max_depth = max_depth\n",
    "        self.depth = 0\n",
    "\n",
    "    def most_IG(self, X, Y, vocabulary):\n",
    "\n",
    "        max_gain = -1\n",
    "        max_word= -1\n",
    "\n",
    "\n",
    "        for w in vocabulary:\n",
    "            x_word = list() #Λίστα με όλες τις τιμές που θα πάρει μια λέξη στον Χ\n",
    "            for ex in range(len(X)):\n",
    "                x_word.append(X[ex][w])\n",
    "            word_ig = IG(Y, x_word) #Στέλνουμε το Υ και την λίστα στον ΙG, για να βρει το informtion gain της λέξης ανάλογικά με το Υ\n",
    "\n",
    "            if(word_ig>max_gain):\n",
    "                max_gain = word_ig\n",
    "                max_word = w\n",
    "\n",
    "        return max_word #Η λέξη με το μέγιστο Information Gain\n",
    "\n",
    "    def fit(self, X, Y, vocabulary, default):\n",
    "       \n",
    "        if(len(Y) == 0):\n",
    "            #αν φτάσαμε εδώ τελείωσαν τα Υ γιατί τελείωσε η κατάταξη κάθε review στο δέντρο.\n",
    "            #Παίρνει για τιμή του classification εκείνη που επικρατούσε στο παραπάνω επίπεδο του δέντρο\n",
    "            node = Tree()\n",
    "            node.classification = default \n",
    "            return node \n",
    "\n",
    "        if(len(set(Y)) == 1):\n",
    "            #Η μέθοδος set επιστρέφει ένα set με όλες τις διαφορετικές τιμές που περιλαμβάνει το όρισμα της, εδώ το Υ\n",
    "            #Άρα φτάσαμε εδώ αν το Υ έχει μόνο μια τιμη, η οποία θα χρησιμοποιηθεί στο classification και σταματάει η διαδικασία. \n",
    "            node = Tree()\n",
    "            node.classification = Y[0]\n",
    "            return node\n",
    "\n",
    "        if(len(vocabulary) == 0):\n",
    "            #Αν φτάσαμε εδώ χρησιμοποιήσαμε όλες τις λέξεις οπότε δεν γίνονται παραπάνω κατατάξεις.\n",
    "            #Η διαδικασία σταματάει και γίνεται classified με την τιμή που επικρατεί στα Y\n",
    "            node = Tree()\n",
    "            if(Y.count(0)>Y.count(1)):\n",
    "                max_count = 0\n",
    "            else:\n",
    "                max_count = 1\n",
    "            node.classification = max_count\n",
    "            return node\n",
    "\n",
    "        if (self.depth == self.max_depth):\n",
    "            #Αν είμαστε εδώ φτάσαμε το max depth του δέντρου\n",
    "            #Η διαδικασία σταματάει και γίνεται classified με την τιμή που επικρατεί στα Y. \n",
    "            #Αν έχουμε ισοπαλία αρνητικών θετικών reviews παίρνουμε το default, δηλαδή αυτή που επικρατούσε στο παραπάνω επίπεδο\n",
    "            yes = True\n",
    "            node = Tree()\n",
    "            if((Y.count(0))>Y.count(1)):\n",
    "                node.classification = 0\n",
    "            elif((Y.count(0))<Y.count(1)):\n",
    "                node.classification = 1\n",
    "            else:\n",
    "                node.classification =default\n",
    "            return node\n",
    "\n",
    "        #Σταματάει η διαδικασία αν υπερτερεί στα εναπομείναντα reviews είτε το 0 είτε το 1\n",
    "        if (float(Y.count(1))/float(len(Y))>= 0.95):\n",
    "            node = Tree()\n",
    "            node.classification = 1                   \n",
    "            return node\n",
    "        \n",
    "        if(float(Y.count(0))/float(len(Y))>= 0.95):\n",
    "            node = Tree()\n",
    "            node.classification = 0\n",
    "            return node\n",
    "\n",
    "        #Αποθήκευση του clssification που επικρατεί μέχρι στιγμης ώστε να περασθεί ως default στα παρακάτω επίπεδα\n",
    "        if(Y.count(1)>Y.count(0)):\n",
    "            max_count = 1\n",
    "        else:\n",
    "            max_count = 0\n",
    "\n",
    "\n",
    "        best_word = self.most_IG(X, Y, vocabulary) #Εύρεση της λέξης με το μέγιστο Information Gain \n",
    "        tree = Tree() #Αρχικοποίηση υπόδεντρου\n",
    "\n",
    "        #το νεο λεξιλόγιο, χωρίς την λέξη που θα χρσιμοποιηθέι για τον διαχωρισμό σε φύλλα τωρα ωστέ να μην ξαναχρησιμοποιηθεί μετά\n",
    "        new_vocabulary = vocabulary.copy() \n",
    "        new_vocabulary.remove(best_word)\n",
    "        self.depth += 1 #ενημέρωση του depth\n",
    "\n",
    "        for zero_or_one in range(2):\n",
    "            # if(zero_or_one==0):\n",
    "            #     print(len(new_vocabulary))\n",
    "            #Oι νέες λίστες reviews, δημιουργούνται 2 για κάθε κατηγορία(Υ και Χ) λόγω της for, μια με τη best_word και μία χωρις \n",
    "            x_new = list()\n",
    "            y_new = list()\n",
    "            for i in range(len(X)):\n",
    "                if X[i][best_word] == zero_or_one:\n",
    "                    x_new.append(X[i])\n",
    "                    y_new.append(Y[i])\n",
    "            subtree = self.fit(x_new, y_new, new_vocabulary, max_count)\n",
    "            subtree.tag = zero_or_one \n",
    "            subtree.word = best_word\n",
    "            tree.new_child(subtree)            \n",
    "                \n",
    "        return tree\n",
    "\n",
    "    def singular_prediction(self, X, tree):\n",
    "        sub_tree = tree #Αρχικοποίηση Υπόδεντρου\n",
    "        flag = False\n",
    "        while not flag:\n",
    "            word_feature = sub_tree.children[0].word #Παίρνουμε τη λέξη με την οποία έγινε ο διαχωρισμός\n",
    "            for sub in sub_tree.children:\n",
    "                if (sub.tag == X[word_feature]): \n",
    "                    #Αν υπάρχει η λέξη-κριτήριο με την οποία έγινε ο διαχωρισμος σε αυτο το επίπεδο στο sample που κοιταμε \n",
    "                    # πάμε στο υπόδεντρο οπόυ το tag είναι 1(δηλ. έχει reviews που την περιλαμβανουν), αλλιώς σε αυτο που ειναι 0\n",
    "                    sub_tree = sub\n",
    "            if(sub_tree.classification == 1 or sub_tree.classification == 0):\n",
    "                #Σταματάμε αν φτάσουμε σε κάποιο φυλλο. Τα φύλλα έχουν τιμή 0 ή 1 και αυτο καταλήγει να ειναι το classification\n",
    "                # του sample. Οι άλλοι ενδιάμεσοι κόμβοι έχουν None στο classification\n",
    "                flag = True\n",
    "        return sub_tree.classification\n",
    "\n",
    "    def predict(self, tree, X):\n",
    "        y_pred = list()\n",
    "        for i in range(len(X)):\n",
    "            y_pred.append(self.singular_prediction(X[i], tree)) #πρόβλεψη για κάθε review ξεχωριστά\n",
    "        \n",
    "        return y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LhNCa4YSzS5J"
   },
   "source": [
    "## Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XyQtFiv8zUV5",
    "outputId": "d46121a7-eecc-492e-ba8a-7cad33aa614f"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Random_Forest():\n",
    "    def __init__(self, num_of_words, trees = 10):\n",
    "        self.num_of_words = num_of_words #Αριθμός των λέξεων\n",
    "        self.trees = trees #Αριθμός των δέντρων που θα φτιαχθούν\n",
    "        self.forest = list() #Λίστα Δέντων\n",
    "\n",
    "    def new_sample(self, X, Y):\n",
    "        #Αρχικοποίηση των νέων x και y\n",
    "        x_new = list()\n",
    "        y_new = list()\n",
    "\n",
    "        y_indexes = list() #Tα indexes των reviews που δεν έχουν επιλεχθεί\n",
    "        for i in range(len(Y)):\n",
    "            y_indexes.append(i)\n",
    "\n",
    "        for i in range(len(X)):\n",
    "            #Τυχαία επιλογή reviews για το υποσύνολο που θα επιστρέψει η μέθοδος, χρησιμοποιώντας τα indexes που φτιάχτηκε πάνω\n",
    "            random_choice = random.choice(y_indexes) \n",
    "            x_new.append(X[random_choice])\n",
    "            y_new.append(Y[random_choice])\n",
    "\n",
    "        return x_new, y_new\n",
    "\n",
    "    def new_vocabulary(self, X):\n",
    "        #Λίστα με τα indexes του λεξιλογιου για τυχαία επιλογή των νέων λέξεων του νέου λεξιλογίου που επιστρέφει η μέθοδος \n",
    "        words_indexes = list()\n",
    "        for x in range(len(X[0])):\n",
    "            words_indexes.append(x)\n",
    "\n",
    "        new_words = list()\n",
    "        for i in range(self.num_of_words):\n",
    "            random_word = random.choice(words_indexes) #Tυχαία επιλογή λέξης\n",
    "            words_indexes.remove(random_word) #Αφαίρεση από το παλιό λεξιλόγιο\n",
    "            new_words.append(random_word) #Εισαγωγή στο καινούριο\n",
    "\n",
    "        return new_words\n",
    "\n",
    "    def fit(self, X, Y, max_depth = 10):\n",
    "        for i in range(self.trees):\n",
    "            id3 = ID3(max_depth) #Δημιουργία id3 δέντρου\n",
    "            random_x, random_y = self.new_sample(X, Y)\n",
    "            tree = id3.fit(random_x, random_y, self.new_vocabulary(random_x), 0)\n",
    "            self.forest.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = list()\n",
    "        for i in range(len(X)):\n",
    "            zeros =0\n",
    "            ones = 0\n",
    "            for j in range(self.trees):\n",
    "                id3 = ID3()\n",
    "                prediction = id3.singular_prediction(X[i], self.forest[j])\n",
    "                if (prediction == 1):\n",
    "                    ones += 1\n",
    "                elif(prediction==0):\n",
    "                    zeros +=1\n",
    "            if ones>zeros:\n",
    "                y_pred.append(1)\n",
    "            else:\n",
    "                y_pred.append(0)\n",
    "        return y_pred"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sklearn-IMDB.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "7b1f2b33e866b0bf2409397e5f58ba9cdf170d3b7f64c8f359c79998e2f88ad4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
